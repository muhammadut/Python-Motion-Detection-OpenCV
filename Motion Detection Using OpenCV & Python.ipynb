{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Detection using OpenCV (A beginner's guide) \n",
    "\n",
    " \n",
    "\n",
    "This notebook is a step-by-step explanation of a simple OpenCV Motion Detection application. \n",
    "\n",
    "This was a  part of a computer vision project I did during my internship at Honda of Canada MFG. \n",
    "\n",
    "I hope you are familiar with some of OpenCV's functions. If not, then don't worry I will try to explain everything in detail as much as possible. \n",
    "\n",
    "\n",
    "## High Level Explanantion:\n",
    "\n",
    "The general idea behind the application is that it takes the first frame from the camera  as a reference. \n",
    "\n",
    "This reference frame is a static background against which we are trying to detect motion.  \n",
    "\n",
    "The program will run & detect changes between the first reference frame and the frames that follow. \n",
    "\n",
    "Basically, \n",
    "\n",
    "We are going to compare pixel difference \"delta\" between the first static reference frame & other frames.\n",
    "\n",
    "If the difference \"delta\" is more than the threshold (that we have defined) it will trigger to draw a box around the areas where the pixel differnence is observed.\n",
    "\n",
    "\n",
    "We will also record times at which the object enters & exits the frame.we will store these values in a Pandas dataframe. And finally, We will visualize these times using Bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Getting started with OpenCV\n",
    "\n",
    "### Webcam basics: \n",
    "\n",
    "__1. Turn on your webcam using OpenCV and Python __\n",
    "\n",
    "To do this we will use the __.VideoCapture()__ method from OpenCV. The input argument is the camera(s) connected to your computer. In our case it is only 1 camera so we will enter 0. If you had 2 or 3 cameras you'd put in 1 or 2.\n",
    "\n",
    "__2. Release the camera__ \n",
    "\n",
    "If you run the first line of code: __video_object = cv2.VideoCapture__(0) below you would notice the light turns on your camera. That is because we have intialized the camera. The light would not turn off. To turn off the camera we would like to use the: \n",
    "__.release() method__. This will turn off the camera or will _release_ it.\n",
    "\n",
    "__3. Holding the camera for a certain amount of time__\n",
    "\n",
    "Now you'd ask that what if I want to run the camera for a certain amount of time? For that we will import _time_ and use the __.sleep() method__ on \"time\" object to tell Python for how long we'd like to hold the camera before it is realeased.\n",
    "\n",
    "So far so good...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # import OpenCV\n",
    "import time # import time to hold the camera for a certain amount of time\n",
    "\n",
    "video_object = cv2.VideoCapture(0) # intialize the camera by creating a video_object\n",
    "\n",
    "time.sleep(3) # hold the camera for 3 seconds \n",
    "\n",
    "video_object.release( ) # release the camera "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Displaying the first frame__: One \"frame\" at a time\n",
    "\n",
    "The way OpenCV works is that it recursively shows each frame. The first frame after, then the next, then the next, so on and so forth. \n",
    "Let's just start by displaying the first frame. And I know you're already thinking in terms of writing a loop to show all the frames as video feed...but just hang on yet! \n",
    "\n",
    "To display anything on your computer screen you would like to use yet another method __.read()__ on your video_object\n",
    "This outputs two 2 things: \n",
    "1. __A Boolean__, True indicates the camera is turned on & works (can be later used to check if the feed is running etc.) \n",
    "2. __A numpy array__ which is basically a representation of the frame as an array of pixel values. This numpy array is very useful as we can perform operations on it directly. \n",
    "\n",
    "Finally to show what we captured, we will use the __.imshow()__ method. This takes 2 arguments: \n",
    "1. Name of the window that will pop up, & \n",
    "2. The frame that you captured using the __.read()__ method\n",
    "\n",
    "\n",
    "__5. Closing the display window:__\n",
    "\n",
    "We can't just let the window hang there & freeze, we would like to close the window or allow the user to press any key & stop the script. This is very important because if you don't include __.waitKey()__ method along with __.destroyAllWindows()__ then your python kernel might crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import cv2 # import OpenCV\n",
    "import time # import time to hold the camera for a certain amount of time\n",
    "\n",
    "video_object = cv2.VideoCapture(0) # intialize the camera by creating a video_object\n",
    "\n",
    "check, frame = video_object.read() # check is a boolean, frame is a numpy array \n",
    "                                   \n",
    "time.sleep(3) # hold the camera for 3 seconds \n",
    "\n",
    "cv2.imshow(\"First Frame Captured\", frame) # a window is created named: 1st arguement, & displays: 2nd argument\n",
    "\n",
    "\n",
    "cv2.waitKey(0) # user presses any key which is represented by 0 as an argument\n",
    "\n",
    "video_object.release() # the camera is released as soon as waitKey is pressed\n",
    "\n",
    "cv2.destroyAllWindows() # All windows are closed\n",
    "\n",
    "\n",
    "print(type(check)) # make sure check is boolean \n",
    "print(type(frame)) # frame is a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we can turn on the webcam, we understand the basic methods in OpenCV. One important thing we learned here is that Python is processing the webcam feed as single images. What does that mean? \n",
    "    It means that we can apply other methods such as converting the images to gray scale, performing computations etc... this is good. \n",
    "    \n",
    "    \n",
    "## __Video Feed!__\n",
    "\n",
    "Ok so now, we want the camera to run a live feed. The simplest way to do it is put the entire block of code above inside a __While loop__ & set it to __True__\n",
    "\n",
    "However we need to make a few modifications first: \n",
    "\n",
    "We can start off first by removing __time.sleep()__\n",
    "\n",
    "Store __.waitKey()__ in a variable called key\n",
    "\n",
    "If the value of this variable is set to something then we stop the video feed.\n",
    "\n",
    "It will make sense when you see the code. Look at the code below first & then read this description in the next Markdown\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 # import OpenCV\n",
    "\n",
    "video_object = cv2.VideoCapture(0) # intialize the camera by creating a video_object\n",
    "\n",
    "while True:\n",
    "    check, frame = video_object.read() # save the frame in a variable called frame\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # convert image to gray scale: because it is 1 frame at a time, we can apply color transformation \n",
    "\n",
    "    cv2.imshow(\"Video Feed inside while loop\", gray_frame) # create a window but this time we pass the gray_frame as argument to show    \n",
    "    \n",
    "    key = cv2.waitKey(1000)  # wait 1 second or 1000 ms before jumping back to the start of the loop\n",
    "    \n",
    "    if key == ord('q'):   # if the user pressed 'q' on their keyboard break the loop \n",
    "        break\n",
    "    \n",
    "\n",
    "video_object.release() # as soon as 'q' is pressed webcam is released \n",
    "\n",
    "cv2.destroyAllWindows() # All windows are closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What did we just do?__\n",
    "\n",
    "OK now, so this is how the script works: \n",
    "\n",
    "1. We initialize the camera feed in an object called video_object... Basically turns the camera on\n",
    "\n",
    "2. We say __while True:__  \n",
    "\n",
    "Save the frame\n",
    "\n",
    "Convert it into a gray-scale-image using the __.cvtColor()__ method. \n",
    "\n",
    "Show the image\n",
    "\n",
    "Wait for 1000 milli seconds == 1 second \n",
    "\n",
    "Go back to the start of the loop & start over again \n",
    "\n",
    "3. If the user decided to press 'q' on his keyboard then release the camera and close all the windows \n",
    "\n",
    "Simple! :) \n",
    "\n",
    "Now, you can run the script... but there is  __LAG!!__ \n",
    "\n",
    "I feel ya. Here is a small quiz for you: What value in the script can we change to make the feed more smooth? \n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    ".\n",
    "You guessed it ! \n",
    "We can lower the waitKey() to a lower number so the while loop runs faster & we get more frames/second\n",
    "\n",
    "Try using the __cv2.waitKey(1)__ & see how it goes. \n",
    "\n",
    "Note: waitKey() only accepts integers! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Motion Detection! \n",
    "\n",
    "## Basic architecture of the application: \n",
    "\n",
    "1. So we would like to achieve motion detection through pixel difference computation.\n",
    "\n",
    "2. We would start off by capturing the first frame in our application as our __static background__ \n",
    "\n",
    "3. We will store this static background (first frame) as a numpy array, which is basically a big matrix\n",
    "\n",
    "4. We will apply matrix subtraction on all the frames that follow. \n",
    "\n",
    "5. If the subtraction is more than a certain value (threshold). We will say motion is detected & draw a box around it. \n",
    "\n",
    "LET'S PROCEED!\n",
    "\n",
    "### Store the first_frame! \n",
    "\n",
    "We would start by storing the first frame. It is a little tricky we will have to use the _continue_ statement\n",
    "\n",
    "So we intialize a variable named __first_frame__  to _None_\n",
    "\n",
    "Inside our _while loop_ we write an __if loop__ \n",
    "\n",
    "On the first iteration: if the value of first_frame is None then take the value from gray_frame & store it in the first_frame variable. \n",
    "\n",
    "Go back to the start of the loop & then run the 2nd iteration.\n",
    "\n",
    "We add a _continue_ because we don't want to go execute the lines below before grabbing the frames that follow. \n",
    "\n",
    "So: 1st iteration the first_frame variable is assinged gray_frame from __.read()__ method which is the first frame\n",
    "\n",
    "_continue_ statement sends us back to the start of the while loop so we can grab the 2nd frame for comparison computation.\n",
    "\n",
    "2nd iteration: the if statement is False because the value of first_frame is __NOT None__ as we assigned it a value in the first iteration \n",
    "\n",
    "The if loop is not executed & we go down doing our computations: \n",
    "\n",
    "## Calculate the delta_frame!: \n",
    "\n",
    "Before we apply any delta computations we would like to do some transformations. These are important to get accurate results & to remove noise. \n",
    "\n",
    "The first transformation we will apply to all the frames is a:\n",
    "\n",
    "__.GaussianBlur()__ which takes in three arguments: \n",
    "\n",
    "1. The frame to apply the transformation on, \n",
    "\n",
    "2. The kernel size (as a tuple of width & height) \n",
    "\n",
    "3. Standard deviation of the blur. You can read more on OpenCV blurs on: https://docs.opencv.org/3.1.0/d4/d13/tutorial_py_filtering.html\n",
    "\n",
    "If you dont wan't to read then we will be using kernel size = (21,21), standard_deviation = 0 which are acceptable numbers for our application. \n",
    "\n",
    "\n",
    "Now, we will finally compute the delta_frame using: \n",
    "\n",
    "__.absdiff() method__ This takes 2 arguments which are the the subtraction matrices you'd like to calculate the difference on\n",
    "\n",
    "Finally, you'd like to show the delta_frame for your own understanding.\n",
    "\n",
    "To do this we will create a new window using __.imshow()__ method.\n",
    "\n",
    "__PLEASE NOTE: DISAPPEAR FROM THE WEBCAM WINDOW BEFORE RUNNING THE SCRIPT & THEN SHOWING UP AS AN OBJECT __ to see the delta_frame properly\n",
    "\n",
    "You will see that in the delta_frame window the background is eliminated & only you appear as a negative.... You get the idea.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "first_frame = None # initalize the first frame to None. This will be our reference static background  \n",
    "\n",
    "video_object = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    check, frame = video_object.read() \n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # convert frame to grayscale\n",
    "    \n",
    "    gray_frame = cv2.GaussianBlur(gray_frame,(21,21),0) # apply blur to remove noise & smoothing\n",
    "    \n",
    "    if first_frame is None: \n",
    "        first_frame = gray_frame\n",
    "        continue  # grab the first frame on 1st iteration & go back to the start of the loop\n",
    "    \n",
    "    delta_frame = cv2.absdiff(first_frame, gray_frame)  # calculate the difference between the first frame & the frames that follow \n",
    "     \n",
    "        \n",
    "    cv2.imshow(\"delta_frame\", delta_frame)    # show the delta frame feed  \n",
    "    cv2.imshow(\"Video Feed inside while loop\", gray_frame)     # just the normal gray scale & blurred feed\n",
    "    \n",
    "    key = cv2.waitKey(1)  \n",
    "    if key == ord('q'):    \n",
    "        break\n",
    "    \n",
    "\n",
    "video_object.release()  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calulate the Threshold!\n",
    "\n",
    "Now that we have our delta_frame we would like calculate the threshold.\n",
    "\n",
    "The idea is that delta_frame is a numpy matrix with integers as values acquired from the subtraction of the first_frame with the current frame. \n",
    "\n",
    "The higher these values in the matrix the greater the difference between the first_frame & the current frame...so something changed between the two\n",
    "\n",
    "You can check out the delta_frame matrix by simply typing \n",
    "__print(delta_frame)__ \n",
    "\n",
    "\n",
    "\n",
    "To calculate the threshold we use: \n",
    "\n",
    "__.threshold() method__ the method takes in 4 arguments: \n",
    "\n",
    "1. The threshold matrix in our case delta_frame\n",
    "2. The threshold limit. I set it to be 30. You can adjust it to your liking\n",
    "3. The color to assign to the pixel coordinates that are more than the threshold. I set it to be 255 which converts them to white color\n",
    "4. The threshold method in our case it is __binary threshold__ \n",
    "\n",
    "The __.threshold()__ method returns a tuple with 2 values: \n",
    "\n",
    "We need the 2nd value of this tuple which is the actual frame we access it by indexing it by using [1] \n",
    "\n",
    "\n",
    "In summary: \n",
    "So, if the intensity of the pixel is higher than threshold limit we defined, then the new pixel intensity is set to 255. Otherwise, the pixels are set to 0. \n",
    "You can read on thresholding at: https://docs.opencv.org/2.4/doc/tutorials/imgproc/threshold/threshold.html\n",
    "\n",
    "We can go ahead & use the threshold_frame & draw boxes on it to indicate motion but before we do that we would want to make the white areas smoother. \n",
    "\n",
    "\n",
    "To _smooth_ out the threshold_frame even more we will finally use: \n",
    "\n",
    "__.dilate() method__  which takes 3 arguments: \n",
    "\n",
    "1. The threshold_frame to perform smoothing on.\n",
    "2. The kernel array for custom dilation. I choose None\n",
    "3. The number of iterations to perform the smoothing. The higher the smoother. I choose 2 as our value.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "first_frame = None \n",
    "video_object = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    check, frame = video_object.read() \n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    gray_frame = cv2.GaussianBlur(gray_frame,(21,21),0) \n",
    "    \n",
    "    if first_frame is None: \n",
    "        first_frame = gray_frame\n",
    "        continue  \n",
    "    \n",
    "    delta_frame = cv2.absdiff(first_frame, gray_frame)\n",
    "    \n",
    "    threshold_frame = cv2.threshold(delta_frame,30,255,cv2.THRESH_BINARY)[1] # extracting the threshold_frame \n",
    "    \n",
    "    threshold_frame = cv2.dilate(threshold_frame, None, iterations = 2) # applying threshold smoothing using dilate\n",
    "        \n",
    "    cv2.imshow(\"threshold frame\", threshold_frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)  \n",
    "    if key == ord('q'):    \n",
    "        break\n",
    "    \n",
    "\n",
    "video_object.release()  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding & Drawing Contours! \n",
    "\n",
    "To find ALL the contours we use the OpenCV's:\n",
    "\n",
    "__.findContours() method__ the method takes 3 arguments: \n",
    "\n",
    " \n",
    "1. The frame to find contours from. \n",
    "2. The contour retrieval mode. \n",
    "3. The approximation method.\n",
    "\n",
    "It outputs 3 values: \n",
    "\n",
    "1. The modified image\n",
    "2. The contours\n",
    "3. The hierarchy\n",
    "\n",
    "You can read more on: https://docs.opencv.org/3.4.0/d4/d73/tutorial_py_contours_begin.html\n",
    "\n",
    "\n",
    "We are interested in the 2nd output from the findContours() method.\n",
    "\n",
    "The 2nd output is all the contours in the current frame, but we are only interested in the contours that are let's just say for example bigger than X-pixels. \n",
    "\n",
    "So we will have to iterate over the contours & say if the area is bigger than X-pixels then draw them. \n",
    "\n",
    "To do so we will use 2 more functions as follows: \n",
    "\n",
    "\n",
    "__.boundingRect():__ It takes in the contour as input & returns 4 values: \n",
    "\n",
    "x coordinate, y coordinate, width, height of the contour\n",
    "\n",
    "Then we use: \n",
    "\n",
    "__.rectangle()__ method to draw a rectange using these coordinated: \n",
    "\n",
    "The inputs are as follows: \n",
    "\n",
    "1. The original frame. \n",
    "2. x, y the upper left corner of the box \n",
    "3. x+w & y+h as the lower right corner of the box \n",
    "4. The color of the box in the form of a tuple\n",
    "5. width \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "first_frame = None \n",
    "video_object = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    check, frame = video_object.read() \n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    gray_frame = cv2.GaussianBlur(gray_frame,(21,21),0) \n",
    "    \n",
    "    if first_frame is None: \n",
    "        first_frame = gray_frame\n",
    "        continue  \n",
    "    \n",
    "    ## delta_frame calculation & smoothing\n",
    "    \n",
    "    delta_frame = cv2.absdiff(first_frame, gray_frame)\n",
    "    threshold_frame = cv2.threshold(delta_frame,30,255,cv2.THRESH_BINARY)[1]  \n",
    "    threshold_frame = cv2.dilate(threshold_frame, None, iterations = 2) \n",
    "    \n",
    "    \n",
    "    ## Finding & drawing contours \n",
    "    \n",
    "    (_,contours,_) = cv2.findContours(threshold_frame.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) ## finding contours \n",
    "    \n",
    "    for contour in contours:\n",
    "        \n",
    "        if cv2.contourArea(contour) < 1000:\n",
    "            continue\n",
    "        \n",
    "        (x,y,w,h) = cv2.boundingRect(contour)\n",
    "        \n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0,255,0), 3)\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"Motion Detection\", frame)\n",
    "               \n",
    "    key = cv2.waitKey(1)  \n",
    "    if key == ord('q'):    \n",
    "        break\n",
    "    \n",
    "\n",
    "video_object.release()  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voila! \n",
    "\n",
    "###  NOTE: Disappear infront of the webcam, then press run, appear infront of the webcam & you will see a green box drawn around you. \n",
    "\n",
    "### That's the motion detection.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
